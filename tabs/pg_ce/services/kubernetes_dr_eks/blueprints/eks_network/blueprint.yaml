tosca_definitions_version: cloudify_dsl_1_5

imports:
  - cloudify/types/types.yaml
  - plugin:cloudify-aws-plugin?version= >=2.9.0
  - plugin:cloudify-helm-plugin
  - plugin:cloudify-kubernetes-plugin?version= >=2.11.0
  - plugin:cloudify-utilities-plugin?version= >=1.22.1

inputs:
  
  aws_access_key_id:
    type: string
    display_label: AWS Access Key ID
    default: { get_secret: aws_access_key_id }

  aws_secret_access_key:
    type: string
    display_label: AWS Secret Access Key
    default: { get_secret: aws_secret_access_key }

  aws_region_name:
    type: string
    display_label: AWS Region Name
    default: 'us-west-1'

  availability_zone_1:
    type: string
    display_label: Availability Zone 1
    default: { concat: [ { get_input: aws_region_name}, 'a' ] }

  availability_zone_2:
    type: string
    display_label: Availability Zone 2
    default: { concat: [ { get_input: aws_region_name}, 'c' ] }

  eks_cluster_name:
    type: string
    display_label: EKS Cluster Name

  eks_nodegroup_name:
    type: string
    display_label: EKS Node Group Name
    default: { concat: [ 'eks_node_group', { get_input: eks_cluster_name } ] }

  kubernetes_version:
    type: string
    display_label: Kubernetes Version
    default: ''

  service_account_name:
    type: string
    display_label: Service Account Name
    default: examples-user

  service_account_namespace:
    type: string
    display_label: Service Account Namespace
    default: default

  ssh_keypair:
    type: string
    display_label: SSH Key Pair
    default: { concat: [ 'eks_key', { get_input: eks_cluster_name } ] }

  agent_key_name:
    type: string
    display_lable: Agent Key Name
    default: agent_key

  chart_name:
    display_label: Chart Name
    description: >
      Chart package name to deploy from repo.
    default: datadog

  repo_name:
    display_label: Repo Name
    description: >
      Name of the repo to add.
    type: string
    default: datadog

  repo_url:
    display_label: Repo URL
    description: >
      Name of the repo to add.
    type: string
    default: 'https://helm.datadoghq.com'

  helm_installation_source:
    display_label: Helm Installation Source
    description: >
      Helm download link.
    type: string
    default: 'https://get.helm.sh/helm-v3.3.1-linux-amd64.tar.gz'
    constraints:
      - pattern: ^https?:\/\/(www\.)?[-a-zA-Z0-9@:%._\+~#=]{1,256}\.[a-zA-Z0-9()]{1,6}\b([-a-zA-Z0-9()@:%_\+.~#?&//=]*)$

dsl_definitions:

  client_config: &client_config
    aws_access_key_id: { get_input: aws_access_key_id }
    aws_secret_access_key: { get_input: aws_secret_access_key }
    region_name: { get_input: aws_region_name }

node_templates:

  keypair:
    type: cloudify.nodes.aws.ec2.Keypair
    properties:
      client_config: *client_config
      cloudify_tagging: false
      resource_config:
        KeyName: { get_input: ssh_keypair }
        PublicKeyMaterial: { get_attribute: [agent_key, public_key_export] }
    relationships:
      - type: cloudify.relationships.depends_on
        target: agent_key

  eks_service_iam_role:
    type: cloudify.nodes.aws.iam.Role
    properties:
      resource_id: { concat: [ 'eks_service_iam_role', { get_input: eks_cluster_name } ] }
      client_config: *client_config
      resource_config:
        RoleName: { concat: [ 'eks_test_role', { get_input: eks_cluster_name } ] }
        Path: !!str /
        AssumeRolePolicyDocument:
          Version: !!str 2012-10-17
          Statement:
            - Effect: Allow
              Principal:
                Service: !!str eks.amazonaws.com
              Action: !!str sts:AssumeRole
    interfaces:
      cloudify.interfaces.lifecycle:
        create:
          implementation: aws.cloudify_aws.iam.resources.role.create
          inputs:
            modify_role_attribute_args:
              - PolicyArn: arn:aws:iam::aws:policy/AmazonEKSServicePolicy
              - PolicyArn: arn:aws:iam::aws:policy/AmazonEKSClusterPolicy

  eks_nodegroup_iam_role:
    type: cloudify.nodes.aws.iam.Role
    properties:
      resource_id: { concat: [ 'eks_nodegroup_iam_role', { get_input: eks_cluster_name } ] }
      client_config: *client_config
      resource_config:
        RoleName: { concat: [ 'eks_nodegroup_test_role', { get_input: eks_cluster_name } ] }
        Path: !!str /
        AssumeRolePolicyDocument:
          Version: !!str 2012-10-17
          Statement:
          - Effect: Allow
            Principal:
              Service: !!str ec2.amazonaws.com
            Action: !!str sts:AssumeRole
    interfaces:
      cloudify.interfaces.lifecycle:
        create:
          implementation: aws.cloudify_aws.iam.resources.role.create
          inputs:
            modify_role_attribute_args:
              - PolicyArn: arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy
              - PolicyArn: arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy
              - PolicyArn: arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly

  vpc:
    type: cloudify.nodes.aws.ec2.Vpc
    properties:
      resource_config:
        CidrBlock: '10.0.0.0/16'
      client_config: *client_config
      Tags:
        - Key: Name
          Value:
            concat:
              - 'vpc-'
              - { get_input: eks_cluster_name }
        - Key:
            concat:
              - kubernetes.io/cluster/
              - { get_input: eks_cluster_name }
          Value: shared
    interfaces:
      cloudify.interfaces.lifecycle:
        create:
          implementation: aws.cloudify_aws.ec2.resources.vpc.create
          inputs:
            modify_vpc_attribute_args:
              EnableDnsHostnames:
                Value: True

  internet_gateway:
    type: cloudify.nodes.aws.ec2.InternetGateway
    properties:
      client_config: *client_config
    relationships:
      - type: cloudify.relationships.connected_to
        target: vpc

  private_subnet_01:
    type: cloudify.nodes.aws.ec2.Subnet
    properties:
      resource_config:
        CidrBlock: '10.0.0.0/24'
        AvailabilityZone: { get_input: availability_zone_1 }
      client_config: *client_config
      Tags:
        - Key: Name
          Value: eks_private_subnet_01
        - Key:
            concat:
              - kubernetes.io/cluster/
              - { get_input: eks_cluster_name }
          Value: shared
        - Key: kubernetes.io/role/internal-elb
          Value: '1'
    relationships:
      - type: cloudify.relationships.depends_on
        target: vpc
      - type: cloudify.relationships.depends_on
        target: internet_gateway

  private_route_table_01:
    type: cloudify.nodes.aws.ec2.RouteTable
    properties:
      client_config: *client_config
    relationships:
      - type: cloudify.relationships.contained_in
        target: vpc
      - type: cloudify.relationships.connected_to
        target: private_subnet_01

  private_subnet_02:
    type: cloudify.nodes.aws.ec2.Subnet
    properties:
      resource_config:
        CidrBlock: '10.0.1.0/24'
        AvailabilityZone: { get_input: availability_zone_2 }
      client_config: *client_config
      Tags:
        - Key: Name
          Value: eks_private_subnet_02
        - Key:
            concat:
              - kubernetes.io/cluster/
              - { get_input: eks_cluster_name }
          Value: shared
        - Key: kubernetes.io/role/internal-elb
          Value: '1'
    relationships:
      - type: cloudify.relationships.depends_on
        target: vpc
      - type: cloudify.relationships.depends_on
        target: internet_gateway

  private_route_table_02:
    type: cloudify.nodes.aws.ec2.RouteTable
    properties:
      client_config: *client_config
    relationships:
      - type: cloudify.relationships.contained_in
        target: vpc
      - type: cloudify.relationships.connected_to
        target: private_subnet_02

  public_subnet_01:
    type: cloudify.nodes.aws.ec2.Subnet
    properties:
      resource_config:
        CidrBlock: '10.0.2.0/24'
        AvailabilityZone: { get_input: availability_zone_1 }
      client_config: *client_config
      Tags:
        - Key: Name
          Value: eks_public_subnet_01
        - Key:
            concat:
              - kubernetes.io/cluster/
              - { get_input: eks_cluster_name }
          Value: shared
        - Key: kubernetes.io/role/elb
          Value: '1'
    relationships:
      - type: cloudify.relationships.depends_on
        target: vpc
      - type: cloudify.relationships.depends_on
        target: internet_gateway
    interfaces:
      cloudify.interfaces.lifecycle:
        poststart:
          implementation: aws.cloudify_aws.ec2.resources.subnet.modify_subnet_attribute
          inputs:
            resource_config:
              MapPublicIpOnLaunch:
                Value: true

  public_subnet_02:
    type: cloudify.nodes.aws.ec2.Subnet
    properties:
      resource_config:
        CidrBlock: '10.0.3.0/24'
        AvailabilityZone: { get_input: availability_zone_2 }
      client_config: *client_config
      Tags:
        - Key: Name
          Value: eks_public_subnet_02
        - Key:
            concat:
              - kubernetes.io/cluster/
              - { get_input: eks_cluster_name }
          Value: shared
        - Key: kubernetes.io/role/elb
          Value: '1'
    relationships:
      - type: cloudify.relationships.depends_on
        target: vpc
      - type: cloudify.relationships.depends_on
        target: internet_gateway
    interfaces:
      cloudify.interfaces.lifecycle:
        poststart:
          implementation: aws.cloudify_aws.ec2.resources.subnet.modify_subnet_attribute
          inputs:
            resource_config:
              MapPublicIpOnLaunch:
                Value: true

  public_route_table_01:
    type: cloudify.nodes.aws.ec2.RouteTable
    properties:
      client_config: *client_config
    relationships:
      - type: cloudify.relationships.contained_in
        target: vpc
      - type: cloudify.relationships.connected_to
        target: public_subnet_01

  public_route_internet_gateway_01:
    type: cloudify.nodes.aws.ec2.Route
    properties:
      resource_config:
        kwargs:
          DestinationCidrBlock: '0.0.0.0/0'
      client_config: *client_config
    relationships:
      - type: cloudify.relationships.contained_in
        target: public_route_table_01
      - type: cloudify.relationships.connected_to
        target: internet_gateway

  public_route_table_02:
    type: cloudify.nodes.aws.ec2.RouteTable
    properties:
      client_config: *client_config
    relationships:
      - type: cloudify.relationships.contained_in
        target: vpc
      - type: cloudify.relationships.connected_to
        target: public_subnet_02

  public_route_internet_gateway_02:
    type: cloudify.nodes.aws.ec2.Route
    properties:
      resource_config:
        kwargs:
          DestinationCidrBlock: '0.0.0.0/0'
      client_config: *client_config
    relationships:
      - type: cloudify.relationships.contained_in
        target: public_route_table_02
      - type: cloudify.relationships.connected_to
        target: internet_gateway

  elastic_ip_01:
   type: cloudify.nodes.aws.ec2.ElasticIP
   properties:
     resource_config:
       kwargs:
         Domain: 'vpc'
     client_config: *client_config

  private_nat_gateway_01:
    type: cloudify.nodes.aws.ec2.NATGateway
    properties:
      client_config: *client_config
      resource_config:
        kwargs:
          ConnectivityType: public
    relationships:
      - type: cloudify.relationships.depends_on
        target: public_subnet_01
      - type: cloudify.relationships.depends_on
        target: elastic_ip_01

  elastic_ip_02:
   type: cloudify.nodes.aws.ec2.ElasticIP
   properties:
     resource_config:
       kwargs:
         Domain: 'vpc'
     client_config: *client_config

  private_nat_gateway_02:
    type: cloudify.nodes.aws.ec2.NATGateway
    properties:
      client_config: *client_config
      resource_config:
        kwargs:
          ConnectivityType: public
    relationships:
      - type: cloudify.relationships.depends_on
        target: public_subnet_02
      - type: cloudify.relationships.depends_on
        target: elastic_ip_02

  route_private_subnet_nat_gateway_01:
    type: cloudify.nodes.aws.ec2.Route
    properties:
      resource_config:
        kwargs:
          DestinationCidrBlock: '0.0.0.0/0'
      client_config: *client_config
    relationships:
      - type: cloudify.relationships.contained_in
        target: private_route_table_01
      - type: cloudify.relationships.connected_to
        target: private_nat_gateway_01
    interfaces:
      cloudify.interfaces.lifecycle:
        stop: {}

  route_private_subnet_nat_gateway_02:
    type: cloudify.nodes.aws.ec2.Route
    properties:
      resource_config:
        kwargs:
          DestinationCidrBlock: '0.0.0.0/0'
      client_config: *client_config
    relationships:
      - type: cloudify.relationships.contained_in
        target: private_route_table_02
      - type: cloudify.relationships.connected_to
        target: private_nat_gateway_02
    interfaces:
      cloudify.interfaces.lifecycle:
        stop: {}

  security_group:
    type: cloudify.nodes.aws.ec2.SecurityGroup
    properties:
      resource_config:
        GroupName: { concat: [ 'EKS_Test_Group', { get_input: eks_cluster_name } ] }
        Description: The group for EKS test.
        VpcId: { get_attribute: [ vpc, aws_resource_id ]}
      client_config: *client_config
      Tags:
        - Key:
            concat:
              - kubernetes.io/cluster/
              - { get_input: eks_cluster_name }
          Value: owned
    relationships:
      - type: cloudify.relationships.depends_on
        target: vpc

  security_group_rules:
    type: cloudify.nodes.aws.ec2.SecurityGroupRuleIngress
    properties:
      client_config: *client_config
      resource_config:
        kwargs:
          IpPermissions:
           - IpProtocol: "-1"
             FromPort: -1
             ToPort: -1
             IpRanges:
              - CidrIp: 0.0.0.0/0
             UserIdGroupPairs: [  { GroupId: { get_attribute: [ security_group, aws_resource_id ] } } ]
    relationships:
      - type: cloudify.relationships.contained_in
        target: security_group

  eks_cluster:
    type: cloudify.nodes.aws.eks.Cluster
    properties:
      resource_config:
        kwargs:
          name: { get_input: eks_cluster_name }
          version: { get_input: kubernetes_version }
          roleArn: { get_attribute: [ eks_service_iam_role, aws_resource_arn ] }
          resourcesVpcConfig:
            subnetIds:
              - { get_attribute: [ private_subnet_01, aws_resource_id ] }
              - { get_attribute: [ private_subnet_02, aws_resource_id ] }
              - { get_attribute: [ public_subnet_01, aws_resource_id ] }
              - { get_attribute: [ public_subnet_02, aws_resource_id ] }
            securityGroupIds:
              - { get_attribute: [ security_group, aws_resource_id ] }
            endpointPublicAccess: True
            endpointPrivateAccess: False
      client_config: *client_config
      store_kube_config_in_runtime: True
    relationships:
      - type: cloudify.relationships.depends_on
        target: eks_service_iam_role
      - type: cloudify.relationships.depends_on
        target: private_subnet_01
      - type: cloudify.relationships.depends_on
        target: private_subnet_02
      - type: cloudify.relationships.depends_on
        target: public_subnet_01
      - type: cloudify.relationships.depends_on
        target: public_subnet_02
      - type: cloudify.relationships.depends_on
        target: security_group
      - type: cloudify.relationships.depends_on
        target: private_nat_gateway_01
      - type: cloudify.relationships.depends_on
        target: private_nat_gateway_02
      - type: cloudify.relationships.depends_on
        target: public_route_internet_gateway_01
      - type: cloudify.relationships.depends_on
        target: public_route_internet_gateway_02

  eks_node_group:
    type: cloudify.nodes.aws.eks.NodeGroup
    properties:
      resource_config:
        kwargs:
          clusterName: { get_input: eks_cluster_name }
          nodegroupName: { get_input: eks_nodegroup_name }
          scalingConfig:
            minSize: 1
            maxSize: 1
            desiredSize: 1
          diskSize: 20
          subnets:
              - { get_attribute: [ private_subnet_01, aws_resource_id ] }
              - { get_attribute: [ private_subnet_02, aws_resource_id ] }
              - { get_attribute: [ public_subnet_01, aws_resource_id ] }
              - { get_attribute: [ public_subnet_02, aws_resource_id ] }
          instanceTypes:
            - t3.medium
          amiType: AL2_x86_64
          nodeRole: { get_attribute: [ eks_nodegroup_iam_role, aws_resource_arn ] }
          remoteAccess:
            ec2SshKey: { get_input: ssh_keypair }
      client_config: *client_config
    relationships:
      - type: cloudify.relationships.depends_on
        target: eks_nodegroup_iam_role
      - type: cloudify.relationships.depends_on
        target: eks_cluster
      - type: cloudify.relationships.depends_on
        target: keypair

  kubernetes_master:
    type: cloudify.kubernetes.nodes.Master
    properties:
      configuration: &kubernetes_master_configuration
        file_content: { get_attribute: [ eks_cluster, kubeconf ] }
    relationships:
      - type: cloudify.relationships.depends_on
        target: eks_node_group
      - type: cloudify.relationships.aws.eks.connected_to_eks_cluster
        target: eks_cluster

  new_service_account:
    type: cloudify.kubernetes.resources.ServiceAccount
    properties:
      client_config:
        configuration: *kubernetes_master_configuration
      definition:
        apiVersion: v1
        kind: ServiceAccount
        metadata:
          name: { get_input: service_account_name }
          namespace: { get_input: service_account_namespace }
      options:
        namespace: { get_input: service_account_namespace }
    relationships:
      - type: cloudify.relationships.depends_on
        target: kubernetes_master
      - type: cloudify.relationships.aws.eks.connected_to_eks_cluster
        target: eks_cluster

  new_role_binding:
    type: cloudify.kubernetes.resources.RoleBinding
    properties:
      client_config:
        configuration: *kubernetes_master_configuration
      definition:
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRoleBinding
        metadata:
          name: { get_input: service_account_name }
        roleRef:
          apiGroup: rbac.authorization.k8s.io
          kind: ClusterRole
          name: cluster-admin
        subjects:
        - kind: ServiceAccount
          name: { get_input: service_account_name }
          namespace: { get_input: service_account_namespace }
      options:
        namespace: { get_input: service_account_namespace }
    relationships:
      - type: cloudify.relationships.depends_on
        target: kubernetes_master
      - type: cloudify.relationships.depends_on
        target: new_service_account
      - type: cloudify.relationships.aws.eks.connected_to_eks_cluster
        target: eks_cluster

  secret:
    type: cloudify.kubernetes.resources.CustomBlueprintDefinedResource
    properties:
      client_config:
        configuration: *kubernetes_master_configuration
      use_external_resource: true
      definition:
        apiVersion: v1
        kind: Secret
        metadata:
          name: {get_attribute: [new_service_account, kubernetes, secrets, 0, name]}
      api_mapping:
        create:
          api: CoreV1Api
          method: create_namespaced_secret
          payload: V1Secret
        read:
          api: CoreV1Api
          method: read_namespaced_secret
        update:
          api: CoreV1Api
          method: replace_namespaced_secret
          payload: V1Secret
        delete:
          api: CoreV1Api
          method: delete_namespaced_secret
          payload: V1DeleteOptions
    relationships:
      - type: cloudify.relationships.depends_on
        target: kubernetes_master
      - type: cloudify.relationships.depends_on
        target: new_role_binding
      - type: cloudify.relationships.depends_on
        target: new_service_account
      - type: cloudify.relationships.aws.eks.connected_to_eks_cluster
        target: eks_cluster
    interfaces:
      cloudify.interfaces.lifecycle:
        delete: {}

  store_token_and_kubeconfig:
    type: cloudify.nodes.Root
    interfaces:
      cloudify.interfaces.lifecycle:
        create:
          implementation: scripts/store_kube_token_and_config.py
          executor: central_deployment_agent
          inputs:
            kube_token: { get_attribute: [ secret, kubernetes, data, token ] }
            kube_config: { get_attribute: [ eks_cluster, kubeconf ] }
    relationships:
      - type: cloudify.relationships.depends_on
        target: secret

  hello_world:
    type: cloudify.kubernetes.resources.FileDefinedResource
    properties:
      client_config:
        configuration:
          api_options:
            host:  { get_attribute: [eks_cluster, kubeconf, clusters, 0, cluster, server ] }
            api_key: { get_attribute: [ store_token_and_kubeconfig, token ] }
            debug: false
            verify_ssl: false
      validate_resource_status: true
      file:
        resource_path: resources/template.yaml
        template_variables:
          APP_NAME: { get_input: eks_cluster_name }
    relationships:
      - type: cloudify.relationships.depends_on
        target: store_token_and_kubeconfig
  
  helm_install:
    type: cloudify.nodes.helm.Binary
    properties:
      use_existing_resource: false
      installation_source: { get_input: helm_installation_source }

  repo:
    type: cloudify.nodes.helm.Repo
    properties:
      resource_config:
        name: { get_input: repo_name }
        repo_url: { get_input: repo_url }
    relationships:
      - target: helm_install
        type: cloudify.helm.relationships.run_on_host
  
  datadog:
    type: cloudify.nodes.helm.Release
    properties:
      client_config:
        configuration:
          file_content: { get_attribute: [ eks_cluster, kubeconf ] }
          api_options:
            api_key: { get_attribute: [ store_token_and_kubeconfig, token ] }
      resource_config:
        name: "datadog"
        chart: { concat: [ { get_input: repo_name }, '/', { get_input: chart_name } ] }
        values_file: resources/datadog.yaml
        set_values:
          - name: datadog.site
            value: datadoghq.eu
          - name: datadog.apiKey
            value: { get_secret: datadog_api_key }
          - name: datadog.apm.enabled
            value: 'true'
    relationships:
      - target: helm_install
        type: cloudify.helm.relationships.run_on_host
      - target: repo
        type: cloudify.relationships.depends_on
      - target: eks_cluster
        type: cloudify.relationships.depends_on

  agent_key:
      type: cloudify.keys.nodes.RSAKey
      properties:
        resource_config:
          key_name: { get_input: agent_key_name }
          openssh_format: true
        use_secret_store: true
        use_secrets_if_exist: true
      interfaces:
        cloudify.interfaces.lifecycle:
          create:
            implementation: keys.cloudify_ssh_key.operations.create
            inputs:
              store_private_key_material: true

capabilities:

  endpoint:
    value: { get_attribute: [eks_cluster, kubeconf, clusters, 0, cluster, server ] }

  connection_details:
    value: *kubernetes_master_configuration
  
  srv_hostname:
    description: Service hostname
    value: { get_attribute: [hello_world, kubernetes, resources/template.yaml#2, status, load_balancer, ingress, 0, hostname] } 

outputs:

  endpoint:
    value: { get_attribute: [eks_cluster, kubeconf, clusters, 0, cluster, server ] }
  
  srv_hostname:
    description: Service hostname
    value: { get_attribute: [hello_world, kubernetes, resources/template.yaml#2, status, load_balancer, ingress, 0, hostname] } 