tosca_definitions_version: cloudify_dsl_1_4

description: Cloudify Nginx blueprint. Deploys Nginx service with Ansible Cloduify plugin.

imports:
  - https://raw.githubusercontent.com/cloudify-community/eaas-example/master/utils/custom_types.yaml
  - cloudify/types/types.yaml
  - plugin:cloudify-fabric-plugin
  - plugin:cloudify-ansible-plugin

inputs:

  infra_name:
    description: >
      Name of infrastructure blueprint to deploy.
    type: string
    constraints:
      - valid_values:
          - azure
          - aws

  # we using the virtual machine image that is under maintenance
  infra_archive:
    description: >
      URL of infra zip file.
    type: string
    default: https://github.com/cloudify-community/cloudify-catalog/raw/6.4.0-build/docker/vm/vm.zip

  infra_exists:
    description: >
      Whether a getting started infrastructure blueprint has already been uploaded to the manager or not.
    default: false

  infra_deployment_id:
    description: The blueprint name, the deployment name.
    default: { concat: [ 'infra-', { get_input: infra_name } ] }

  website_message:
    type: string
    description: A message to display on the home page of the deployed web server
    default: Welcome to Redis, deployed by Cloudify

node_templates:

  #we creating the prefix for the deployment resources i.e. infrastructure
  infra_prefix:
    type: eaas.nodes.UniquePrefixGenerator
    properties:
      predefined_value: ""

  #generating the password for the wordpress sql client
  master_password:
    type: cloudify.nodes.Root
    interfaces:
      cloudify.interfaces.lifecycle:
        create:
          executor: central_deployment_agent
          implementation: scripts/generate-password.sh

  # deployment of the infrastructure, we pass the URL as a blueprint archive
  # the node will automatically fetch the file from the URL host and unzip it
  # we point the node to use particular infrastructure cloud provider within 
  # main_file_name param by setting infra_name input as the file name value
  infrastructure:
    type: cloudify.nodes.Component
    properties:
      resource_config:
        blueprint:
          blueprint_archive: { get_input: infra_archive }
          main_file_name: { concat: [ { get_input: infra_name }, '.yaml' ] }
          external_resource: { get_input: infra_exists }
        deployment:
          id: { concat: [ get_attribute: [ infra_prefix, value ], "-", { get_input: infra_deployment_id } ] }
    relationships:
      - type: cloudify.relationships.depends_on
        target: infra_prefix
  
  # # we setting the wordpress port to be open
  secrurity_group_rules:
    type: cloudify.nodes.Component
    properties:
      resource_config:
        blueprint:
          blueprint_archive: "security_group.zip"
          main_file_name: { concat: [ { get_input: infra_name }, '.yaml' ] }
          external_resource: false
        deployment:
          id: { concat: [ get_attribute: [ infra_prefix, value ], "-security-group" ] }
          inputs:
            vpc_id: { get_capability: [ { concat: [ get_attribute: [ infra_prefix, value ], "-", { get_input: infra_deployment_id } ] } , vpc_id ] }
            security_group_id: { get_capability: [ { concat: [ get_attribute: [ infra_prefix, value ], "-", { get_input: infra_deployment_id } ] } , security_group_id ] }
    relationships:
      - type: cloudify.relationships.depends_on
        target: infrastructure

  # deployment of the service is made by ansible plugin which run the code 
  # inside the 'install_wordpress.yaml' playbook
  wordpress:
    type: cloudify.nodes.ansible.Playbook
    interfaces:
      cloudify.interfaces.lifecycle:
        poststart: {}
    relationships:
      - type: cloudify.ansible.relationships.run_on_host
        target: infrastructure
        source_interfaces:
          cloudify.interfaces.relationship_lifecycle:
            establish:
              inputs:
                playbook_path: playbooks/install_kafka.yaml
                sources:
                  instances:
                    hosts:
                      instance:
                        ansible_host: { get_capability: [ { concat: [ get_attribute: [ infra_prefix, value ], "-", { get_input: infra_deployment_id } ] } , endpoint ] }
                        ansible_user:  { get_capability: [ { concat: [ get_attribute: [ infra_prefix, value ], "-", { get_input: infra_deployment_id } ] }, user ] }
                        ansible_ssh_private_key_file:  { get_capability: [ { concat: [ get_attribute: [ infra_prefix, value ], "-", { get_input: infra_deployment_id } ] }, key_content ] }
                        ansible_become: true
                        ansible_ssh_common_args: -o StrictHostKeyChecking=no
                run_data:
                  master_password: { get_attribute: [ master_password, master_password ] }

outputs:

  kafka_endpoint:
    description: Kafka Endpoint
    value: { concat : [ "http://", { get_capability: [ { concat: [ get_attribute: [ infra_prefix, value ], "-", { get_input: infra_deployment_id } ] }, endpoint] } ] }